{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef228d8",
   "metadata": {},
   "source": [
    "# Intro Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f70cff",
   "metadata": {},
   "source": [
    "## First Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c904c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:09:04 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394fb4b8a51140b7aa322bb0ecbae14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:09:05 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-11-28 12:09:05 INFO: Using device: cpu\n",
      "2023-11-28 12:09:05 INFO: Loading: tokenize\n",
      "2023-11-28 12:09:05 INFO: Loading: pos\n",
      "2023-11-28 12:09:06 INFO: Loading: lemma\n",
      "2023-11-28 12:09:06 INFO: Loading: constituency\n",
      "2023-11-28 12:09:06 INFO: Loading: depparse\n",
      "2023-11-28 12:09:06 INFO: Loading: sentiment\n",
      "2023-11-28 12:09:07 INFO: Loading: ner\n",
      "2023-11-28 12:09:07 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Barack PROPN\n",
      "Obama Obama PROPN\n",
      "was be AUX\n",
      "born bear VERB\n",
      "in in ADP\n",
      "Hawaii Hawaii PROPN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "doc = nlp('Barack Obama was born in Hawaii.')\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "  for word in sentence.words:\n",
    "    print(word.text, word.lemma, word.pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52f80e",
   "metadata": {},
   "source": [
    "# Redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b15c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:02:40 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e0f90d3d7b4a179d1f1c6dd8f5334e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:02:41 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2023-11-28 12:02:41 WARNING: GPU requested, but is not available!\n",
      "2023-11-28 12:02:41 INFO: Using device: cpu\n",
      "2023-11-28 12:02:41 INFO: Loading: tokenize\n",
      "2023-11-28 12:02:41 INFO: Loading: pos\n",
      "2023-11-28 12:02:41 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"Barack\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 6\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"Obama\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"start_char\": 7,\n",
      "      \"end_char\": 12\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"was\",\n",
      "      \"upos\": \"AUX\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
      "      \"start_char\": 13,\n",
      "      \"end_char\": 16\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"born\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBN\",\n",
      "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
      "      \"start_char\": 17,\n",
      "      \"end_char\": 21\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"in\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"start_char\": 22,\n",
      "      \"end_char\": 24\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"Hawaii\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"start_char\": 25,\n",
      "      \"end_char\": 31\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"start_char\": 31,\n",
      "      \"end_char\": 32\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,pos', use_gpu=True, pos_batch_size=3000) # Build the pipeline, specify part-of-speech processor's batch size\n",
    "\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\") # Run the pipeline on the input text\n",
    "\n",
    "print(doc) # Look at the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f050e3",
   "metadata": {},
   "source": [
    "# Multiple Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813c0247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:04:34 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f48836d6d64366bd0437db0d638f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:04:35 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-11-28 12:04:35 INFO: Using device: cpu\n",
      "2023-11-28 12:04:35 INFO: Loading: tokenize\n",
      "2023-11-28 12:04:35 INFO: Loading: pos\n",
      "2023-11-28 12:04:36 INFO: Loading: lemma\n",
      "2023-11-28 12:04:36 INFO: Loading: constituency\n",
      "2023-11-28 12:04:36 INFO: Loading: depparse\n",
      "2023-11-28 12:04:37 INFO: Loading: sentiment\n",
      "2023-11-28 12:04:37 INFO: Loading: ner\n",
      "2023-11-28 12:04:37 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"I\",\n",
      "      \"lemma\": \"I\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"PRP\",\n",
      "      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 1,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"wrote\",\n",
      "      \"lemma\": \"write\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 2,\n",
      "      \"end_char\": 7,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"another\",\n",
      "      \"lemma\": \"another\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 8,\n",
      "      \"end_char\": 15,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"document\",\n",
      "      \"lemma\": \"document\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"obj\",\n",
      "      \"start_char\": 16,\n",
      "      \"end_char\": 24,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"for\",\n",
      "      \"lemma\": \"for\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 25,\n",
      "      \"end_char\": 28,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"fun\",\n",
      "      \"lemma\": \"fun\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 29,\n",
      "      \"end_char\": 32,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 32,\n",
      "      \"end_char\": 33,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang=\"en\") # Initialize the default English pipeline\n",
    "\n",
    "documents = [\"This is a test document.\", \"I wrote another document for fun.\"] # Documents that we are going to process\n",
    "\n",
    "in_docs = [stanza.Document([], text=d) for d in documents] # Wrap each document with a stanza.Document object\n",
    "\n",
    "out_docs = nlp(in_docs) # Call the neural pipeline on this list of documents\n",
    "\n",
    "print(out_docs[1]) # The output is also a list of stanza.Document objects, each output corresponding to an input Document object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa024c60",
   "metadata": {},
   "source": [
    "## Bulk Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7f257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:10:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32186effc7fd4901975222dc3f29cfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 12:10:20 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-11-28 12:10:20 INFO: Using device: cpu\n",
      "2023-11-28 12:10:20 INFO: Loading: tokenize\n",
      "2023-11-28 12:10:20 INFO: Loading: pos\n",
      "2023-11-28 12:10:20 INFO: Loading: lemma\n",
      "2023-11-28 12:10:20 INFO: Loading: constituency\n",
      "2023-11-28 12:10:21 INFO: Loading: depparse\n",
      "2023-11-28 12:10:21 INFO: Loading: sentiment\n",
      "2023-11-28 12:10:21 INFO: Loading: ner\n",
      "2023-11-28 12:10:22 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"I\",\n",
      "      \"lemma\": \"I\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"PRP\",\n",
      "      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 1,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"wrote\",\n",
      "      \"lemma\": \"write\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 2,\n",
      "      \"end_char\": 7,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"another\",\n",
      "      \"lemma\": \"another\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 8,\n",
      "      \"end_char\": 15,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"document\",\n",
      "      \"lemma\": \"document\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"obj\",\n",
      "      \"start_char\": 16,\n",
      "      \"end_char\": 24,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"for\",\n",
      "      \"lemma\": \"for\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 25,\n",
      "      \"end_char\": 28,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"fun\",\n",
      "      \"lemma\": \"fun\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 29,\n",
      "      \"end_char\": 32,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 32,\n",
      "      \"end_char\": 33,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang=\"en\") # Initialize the default English pipeline\n",
    "\n",
    "documents = [\"This is a test document.\", \"I wrote another document for fun.\"] # Documents that we are going to process\n",
    "\n",
    "out_docs = nlp.bulk_process(documents) # Call the neural pipeline on this list of documents\n",
    "\n",
    "print(out_docs[1]) # The output is also a list of stanza.Document objects, each output corresponding to an input Document object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a93d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfa331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409ab43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889dc2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeccbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0526371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612cc7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823a28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742cd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece306d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
